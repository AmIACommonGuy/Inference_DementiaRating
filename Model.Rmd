---
title: "model"
author: "Ziming Huang"
date: "4/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(ggplot2)
library(VGAM)
library(lmtest)
library(dplyr)
library(generalhoslem)
library(gofcat)
library(DescTools)
library(kableExtra)
```

```{r load data}
## Set pwd to the project folder
## Project choice 2
dementia = read.csv("~/Downloads/mds_center9661.csv", stringsAsFactors = T)
dim(dementia)
```

## Data Cleaning and Variable Selection

```{r}
var <- c("EDUC", "SEX", "MARISTAT", "RACE", "RESIDENC", "DEP", "FEVALAGE", "CDR", "RLDEM")
df <- dementia[, var]

## Relevel marriage status: 0:Never married 1:Divorced 2:Married 3:Widowed 4:Separated
df$MARISTAT <-factor(df$MARISTAT, levels = c('Never married','Divorced','Married','Widowed','Separated'))
df$MARISTAT <- relevel(df$MARISTAT, ref = 'Never married')

## Residence type
df$RESIDENC <- factor(df$RESIDENC, levels = c('Private residence', 'Retirement community', 'Other', 'Assisted living/boarding home/adult family home', 'Skilled nursing facility/nursing home'))
df$RESIDENC <- relevel(df$RESIDENC, ref = 'Other')

## Education coded as categorical variable based on the quantile
quantile(df$EDUC,probs = c(0,0.25,0.5,0.75,1))
## adjust it to give it meaning
cut_p <- c(0, 12, 14, 18, 25)
df$EDUC_cat <- cut(df$EDUC, breaks = cut_p, labels = c('A','B','C','D'))
## CDR:
df$CDR <- factor(df$CDR, levels = c(0.0,0.5,1.0), ordered = F)
df$CDR_ord <- factor(df$CDR, ordered = T)
```

## analysis on residenc

```{r}
t1 = data.frame(table(dementia$RESIDENC,dementia$CDR))
colnames(t1)[1:2] = c('Res','CDR')
(x1 = xtabs(data = t1, Freq ~ Res + CDR))
x1 = x1[-2,]
(ct <- chisq.test(x1, simulate.p.value = TRUE))
ct$residuals
ct$p.value ## not independent

## To deal with the unbalance and other, we combine res into private vs non-private
df$RES_PRIVATE <- df$RESIDENC == 'Private residence'
t2 = data.frame(table(df$RES_PRIVATE,dementia$CDR))
colnames(t2)[1:2] = c('Res','CDR')
(x2 = xtabs(data = t2, Freq ~ Res + CDR))
x2 = x2[-2,]
(ct <- chisq.test(x2, simulate.p.value = TRUE))
ct$residuals
ct$p.value ## not independent, we still preserve the association. Binary res seems valid!
```

```{r}
table(df$MARISTAT)
t3 = data.frame(table(dementia$MARISTAT,dementia$CDR))
colnames(t3)[1:2] = c('marriage','CDR')
(x3 = xtabs(data = t3, Freq ~ marriage + CDR))
(ct <- chisq.test(x3, simulate.p.value = TRUE))
ct$residuals
ct$p.value ## not independent
## To address this we combine marriage into binary 

df$Marriage <- df$MARISTAT == 'Married'
t4 = data.frame(table(df$Marriage,dementia$CDR))
colnames(t4)[1:2] = c('marriage','CDR')
(x4 = xtabs(data = t4, Freq ~ marriage + CDR))
(ct <- chisq.test(x4, simulate.p.value = TRUE))
ct$residuals
ct$p.value ## not independent

```

## Model fitting:

This is continuous education

```{r}
multi_glm <- vglm(df$CDR ~ df$EDUC, family = multinomial(refLevel = 1))
multi_glm_null <- vglm(df$CDR ~ 1, family = multinomial())
waldtest(multi_glm, multi_glm_null)
lrtest_vglm(multi_glm, multi_glm_null)
```

categorical education

```{r}
multi_glm <- vglm(df$CDR ~ df$EDUC_cat, family = multinomial(refLevel = 1))
multi_glm_null <- vglm(df$CDR ~ 1, family = multinomial())
waldtest(multi_glm, multi_glm_null)
lrtest_vglm(multi_glm, multi_glm_null)
```

Doesn't really matter which one we use. Our main covariate education is significant! We want to use categorical to increase intepretability.

## Cummulative model:

There is obvious trend within cdr, so we want to check the cummulative model for it!

```{r}
cumu_glm <- vglm(df$CDR_ord ~ df$EDUC_cat, family = cumulative(link = 'logitlink', parallel = F))
cumu_glm_null <- vglm(df$CDR_ord ~ 1, family = cumulative(link = 'logitlink', parallel = F))
waldtest(cumu_glm, cumu_glm_null)
lrtest_vglm(cumu_glm, cumu_glm_null)
```

further we want to check if the effect of education is homogenous

```{r}
cumu_glm_T <- vglm(df$CDR_ord ~ df$EDUC_cat, family = cumulative(link = 'logitlink', parallel = T))
lrtest_vglm(cumu_glm, cumu_glm_T)
```

No, it is not statistically correct to assume proportionality assumption.

## Main model regression:

we first want to check vif before adding confounders (based on literature review)

```{r}
df$s1 <- (as.numeric(df$CDR)<=1)*1
df$s2 <- (as.numeric(df$CDR)<=2)*1
sm1 <- glm(data = df, s1~EDUC_cat + SEX + MARISTAT + DEP + FEVALAGE + 
    RES_PRIVATE,family = binomial())
sm2 <- glm(data = df, s2~EDUC_cat + SEX + MARISTAT + DEP + FEVALAGE + 
    RES_PRIVATE + RACE,family = binomial())
```

There is no colinearity

```{r}
main_model_F <- vglm(data = df, 
             CDR_ord ~ EDUC_cat +SEX+ Marriage+ RACE + RES_PRIVATE + DEP + FEVALAGE,
             family = cumulative('logitlink', parallel = F))
summary(main_model_F)
logLik.vlm(main_model_F)
```

The loglik is not reasonable! The non-parallelism assumption has resulted in intersecting linear/additive predictors.

```{r}
## To avoid the unreasonable model, i wrote it myself
cumf_m1 <- glm(data = df, s1~EDUC_cat + SEX + Marriage + DEP + FEVALAGE + 
    RES_PRIVATE, family = binomial())
cumf_m2 <- glm(data = df, s2~EDUC_cat + SEX + Marriage + DEP + FEVALAGE + 
    RES_PRIVATE + RACE,family = binomial())
ll1 <- logLik(cumf_m1)
ll2 <- logLik(cumf_m2)
ll1+ll2
```

```{r}
main_model_T <- vglm(data = df, 
             CDR_ord ~ EDUC_cat +SEX+ Marriage+ RACE + RES_PRIVATE + DEP + FEVALAGE,
             family = cumulative('logitlink', parallel = T))
```

we will stick to this model = T

```{r}
main_model <- vglm(data = df, 
             CDR_ord ~ EDUC_cat +SEX+ Marriage + RACE + RES_PRIVATE + DEP + FEVALAGE,
             family = cumulative('logitlink', parallel = T))
summary(main_model)
#PseudoR2(MF, which = c("CoxSnell","Nagelkerke","McFadden"))
```

## Interactions:

Add interaction based on aic

```{r}
fit0 <- vglm(data = df, 
             CDR_ord ~ EDUC_cat*(SEX+Marriage+ DEP + FEVALAGE + RES_PRIVATE + RACE),
             family = cumulative('logitlink', parallel = T))
summary(fit0)
```

```{r}
step4vglm(fit0)
```

According to both direction selection + literature review: CDR_ord \~ EDUC_cat + SEX + Marriage + DEP + FEVALAGE + RACE RES_PRIVATE + EDUC_cat:FEVALAGE + EDUC_cat:RES_PRIVATE is the best one we get.

```{r}
fm <- vglm(CDR_ord ~ EDUC_cat + SEX + Marriage + DEP + FEVALAGE + RACE+
    RES_PRIVATE + EDUC_cat:FEVALAGE + EDUC_cat:RES_PRIVATE, data = df,family = cumulative("logitlink", 
    parallel = T))
summary(fm)
```

```{r}
## check linearity for age
df$FEVALAGE2=df$FEVALAGE^2
fm2 <- vglm(CDR_ord ~ EDUC_cat + SEX + Marriage + DEP + FEVALAGE + FEVALAGE2 + RACE+
    RES_PRIVATE + EDUC_cat:FEVALAGE + EDUC_cat:RES_PRIVATE, data = df,family = cumulative("logitlink", 
    parallel = T))
lrtest_vglm(fm2,fm)
```

The non-linear effect is not significant

```{r}
#marriage, residence, FEVALAGE are issues
mainF1 <- vglm(data = df, 
             CDR_ord ~ EDUC_cat,
             family = cumulative('logitlink', parallel = F))
mainF2<-update(mainF1, .~.+SEX)
mainF3<-update(mainF2, .~.+DEP)
mainF4<-update(mainF3, .~.+Marriage)
#marriage has issues. (lol not a divorce joke)
mainF5<-update(mainF3, .~.+RACE)
mainF6<-update(mainF5, .~.+FEVALAGE)
#FEVALAGE is an issue, makes sense because that's the only non-categorical so there's 
#a lot of different lines it's trying to fit.
mainF7<-update(mainF5, .~.+EDUC_cat:RES_PRIVATE)
#breaks because too many lines
mainFfinal<-update(mainF3, .~.+RACE)
summary(mainFfinal)
AIC(mainFfinal)
```

```{r}
summary(fm)

AIC(fm)
BIC(fm)

n = dim(df)[1]
prob_table <- exp(predict(fm))/(1+exp(predict(fm)))
prob_table <- cbind(prob_table[,1], prob_table[,2]-prob_table[,1], 1-prob_table[,2])
prediction = apply(d, 1, which.max)
(accuracy = sum(df$CDR == (prediction-1)*0.5)/n)
```

Veera said no to the binary logistic regression.

```{r}
## accuracy for parrellal = F coding
sm1 <- glm(data = df, s1~EDUC_cat + SEX + Marriage + DEP + FEVALAGE + 
    RES_PRIVATE + EDUC_cat:FEVALAGE+RACE +EDUC_cat:RES_PRIVATE,family = binomial())
sm2 <- glm(data = df, s2~EDUC_cat + SEX + Marriage + DEP + FEVALAGE + 
    RES_PRIVATE + RACE +EDUC_cat:FEVALAGE+EDUC_cat:RES_PRIVATE,family = binomial())
pm1 <- predict(sm1)
a=exp(pm1)/(1+exp(pm1))
pm2 <- predict(sm2)
b=exp(pm2)/(1+exp(pm2))
d <- cbind(a,b-a,1-b)
e = apply(d, 1, which.max)
e= apply(d, 1, which.max)
(accuracy = sum(df$CDR == (e-1)*0.5)/n)
```

```{r}
# McFadden's pseudo-R^2
null_fm <- vglm(CDR_ord ~ 1, data = df,family = cumulative("logitlink", 
    parallel = T))
lrtest_vglm(null_fm, fm)
print(pseudo_R2 <- 1 - deviance(fm) / deviance(null_fm))
```

## Hoslem

```{r}
logitgof(df$CDR, fitted(fm), ord= T, g = 5)

hl_table <- function(data,model){
  table <- matrix(NA,nrow=10,ncol=2)
  row_tally<-1
  for(gval in 2:11) {
      table[row_tally,1] <-gval
      table[row_tally,2] <-logitgof(data, model, ord= T, g = gval)$p.value
      row_tally<-row_tally+1
  }
  colnames(table)<-list(c("g parameter"), c("p-value"))
table
}
kable(hl_table(df$CDR, fitted(fm)))
```



## Graphs

Woman 1: unmarried non-white woman, with quantile 3 education, with depression in a private residence
*which intercept do we use??*
Woman 1: unmarried non-white woman, with quantile 3 education, with depression in a private residence (intercept 1)
Woman 2: unmarried non-white woman, with quantile 1 education, with depression in a private residence (intercept 1)
Man1<-married white man quantile 4 education, no depression private residence
Man2<-married white man quantile 1 education, no depression, public residence.

```{r}
woman1<-function(x){plogis(3.217459+3.039931+-1.330370-0.046109*x+1.539297-0.038704*x+1.072787)}
woman2<-function(x){plogis(3.217459+-1.330370-0.046109*x+1.539297-0.038704*x+1.072787)}
man1<-function(x){plogis(3.217459+-1.916881-1.023344-0.662878-0.046109*x+0.116408+1.539297-0.038704*x+1.019062)}
man2<-function(x){plogis(3.217459+-1.023344-0.662878-0.046109*x+0.116408)}
p<-ggplot(df, aes(x=FEVALAGE))

p+stat_function(fun=woman1, color="red")+
  stat_function(fun=woman2, color="blue")+
  stat_function(fun=man1, color="black")+
  stat_function(fun=man2, color="black", linetype="dashed")+
  ggtitle("Predictive Cumulative Odds")+
  labs(x="age", y="Probability of No or Mild Impairment")
```



